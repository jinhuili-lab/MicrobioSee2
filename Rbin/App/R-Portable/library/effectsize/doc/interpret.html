<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Automated Interpretation of Indices of Effect Size</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Automated Interpretation of Indices of
Effect Size</h1>


<div id="TOC">
<ul>
<li><a href="#why" id="toc-why">Why?</a></li>
<li><a href="#correlation-r" id="toc-correlation-r">Correlation
<em>r</em></a></li>
<li><a href="#standardized-difference-d-cohens-d" id="toc-standardized-difference-d-cohens-d">Standardized Difference
<em>d</em> (Cohen’s <em>d</em>)</a></li>
<li><a href="#odds-ratio-or" id="toc-odds-ratio-or">Odds Ratio
(OR)</a></li>
<li><a href="#coefficient-of-determination-r2" id="toc-coefficient-of-determination-r2">Coefficient of determination
(R<sup>2</sup>)</a>
<ul>
<li><a href="#for-linear-regression" id="toc-for-linear-regression">For
Linear Regression</a></li>
<li><a href="#for-pls-sem-r-squared-of-latent-variables" id="toc-for-pls-sem-r-squared-of-latent-variables">For PLS / SEM
R-Squared of <em>latent</em> variables</a></li>
</ul></li>
<li><a href="#omega-eta-epsilon-squared" id="toc-omega-eta-epsilon-squared">Omega / Eta / Epsilon
Squared</a></li>
<li><a href="#kendalls-coefficient-of-concordance" id="toc-kendalls-coefficient-of-concordance">Kendall’s coefficient of
concordance</a></li>
<li><a href="#cohens-g" id="toc-cohens-g">Cohen’s <em>g</em></a></li>
<li><a href="#interpretation-of-other-indices" id="toc-interpretation-of-other-indices">Interpretation of other
Indices</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<div id="why" class="section level2">
<h2>Why?</h2>
<p>The metrics used in statistics (indices of fit, model performance, or
parameter estimates) can be very abstract. A long experience is required
to intuitively <strong><em>feel</em></strong> the meaning of their
values. In order to facilitate the understanding of the results they are
facing, many scientists use (often implicitly) some set of <strong>rules
of thumb</strong>. Some of these rules of thumb have been standardize
and validated and subsequently published as guidelines. Understandably
then, such rules of thumb are just suggestions and there is nothing
universal about them. The interpretation of <strong>any</strong> effect
size measures is always going to be relative to the discipline, the
specific data, and the aims of the analyst. This is important because
what might be considered a small effect in psychology might be large for
some other field like public health.</p>
<p>One of the most famous interpretation grids was proposed by
<strong>Cohen (1988)</strong> for a series of widely used indices, such
as the correlation <strong>r</strong> (<em>r</em> = .20, small;
<em>r</em> = .40, moderate and <em>r</em> = .60, large) or the
<strong>standardized difference</strong> (<em>Cohen’s d</em>). However,
there is now a clear evidence that Cohen’s guidelines (which he himself
later disavowed; Funder, 2019) are much too stringent and not
particularly meaningful taken out of context <span class="citation">(Funder and Ozer 2019)</span>. This led to the
emergence of a literature discussing and creating new sets of rules of
thumb.</p>
<p>Although <strong>everybody</strong> agrees on the fact that effect
size interpretation in a study should be justified with a rationale (and
depend on the context, the field, the literature, the hypothesis, etc.),
these pre-baked rules can nevertheless be useful to give a rough idea or
frame of reference to understand scientific results.</p>
<p>The package <strong><code>effectsize</code></strong> catalogs such
sets of rules of thumb for a variety of indices in a flexible and
explicit fashion, helping you understand and report your results in a
scientific yet meaningful way. Again, readers should keep in mind that
these thresholds, as ubiquitous as they may be, <strong>remain
arbitrary</strong>. Thus, their use should be discussed on a
case-by-case basis depending on the field, hypotheses, prior results,
and so on, to avoid their crystallization, as for the infamous <span class="math inline">\(p &lt; .05\)</span> criterion of hypothesis
testing.</p>
<p>Moreover, some authors suggest the counter-intuitive idea that
<em>very large effects</em>, especially in the context of psychological
research, is likely to be a “gross overestimate that will rarely be
found in a large sample or in a replication” <span class="citation">(Funder and Ozer 2019)</span>. They suggest that
smaller effect size are worth taking seriously (as they can be
potentially consequential), as well as more believable.</p>
</div>
<div id="correlation-r" class="section level2">
<h2>Correlation <em>r</em></h2>
<p>There can be used to interpret not only Pearson’s correlation
coefficient, but also Spearman’s, <span class="math inline">\(\phi\)</span> (phi), Cramer’s <em>V</em> and
Tschuprow’s <em>T</em>. Although Cohen’s <em>w</em> and Pearson’s
<em>C</em> are <em>not</em> a correlation coefficients, they are often
also interpreted as such.</p>
<div id="funder2019evaluating" class="section level4">
<h4><span class="citation">Funder and Ozer (2019)</span></h4>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">interpret_r</span>(x, <span class="at">rules =</span> <span class="st">&quot;funder2019&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.05</strong> - Tiny</p></li>
<li><p><strong>0.05 &lt;= r &lt; 0.1</strong> - Very small</p></li>
<li><p><strong>0.1 &lt;= r &lt; 0.2</strong> - Small</p></li>
<li><p><strong>0.2 &lt;= r &lt; 0.3</strong> - Medium</p></li>
<li><p><strong>0.3 &lt;= r &lt; 0.4</strong> - Large</p></li>
<li><p><strong>r &gt;= 0.4</strong> - Very large</p></li>
</ul>
</div>
<div id="gignac2016effect" class="section level4">
<h4><span class="citation">Gignac and Szodorai (2016)</span></h4>
<p>Gignac’s rules of thumb are actually one of few interpretation grid
justified and based on actual data, in this case on the distribution of
effect magnitudes in the literature.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">interpret_r</span>(x, <span class="at">rules =</span> <span class="st">&quot;gignac2016&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.1</strong> - Very small</p></li>
<li><p><strong>0.1 &lt;= r &lt; 0.2</strong> - Small</p></li>
<li><p><strong>0.2 &lt;= r &lt; 0.3</strong> - Moderate</p></li>
<li><p><strong>r &gt;= 0.3</strong> - Large</p></li>
</ul>
</div>
<div id="cohen1988statistical" class="section level4">
<h4><span class="citation">J. Cohen (1988)</span></h4>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">interpret_r</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1988&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.1</strong> - Very small</p></li>
<li><p><strong>0.1 &lt;= r &lt; 0.3</strong> - Small</p></li>
<li><p><strong>0.3 &lt;= r &lt; 0.5</strong> - Moderate</p></li>
<li><p><strong>r &gt;= 0.5</strong> - Large</p></li>
</ul>
</div>
<div id="evans1996straightforward" class="section level4">
<h4><span class="citation">Evans (1996)</span></h4>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">interpret_r</span>(x, <span class="at">rules =</span> <span class="st">&quot;evans1996&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.2</strong> - Very weak</p></li>
<li><p><strong>0.2 &lt;= r &lt; 0.4</strong> - Weak</p></li>
<li><p><strong>0.4 &lt;= r &lt; 0.6</strong> - Moderate</p></li>
<li><p><strong>0.6 &lt;= r &lt; 0.8</strong> - Strong</p></li>
<li><p><strong>r &gt;= 0.8</strong> - Very strong</p></li>
</ul>
</div>
<div id="lovakov2021empirically" class="section level4">
<h4><span class="citation">Lovakov and Agadullina (2021)</span></h4>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">interpret_r</span>(x, <span class="at">rules =</span> <span class="st">&quot;lovakov2021&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.12</strong> - Very small</p></li>
<li><p><strong>0.12 &lt;= r &lt; 0.24</strong> - Small</p></li>
<li><p><strong>0.24 &lt;= r &lt; 0.41</strong> - Moderate</p></li>
<li><p><strong>r &gt;= 0.41</strong> - Large</p></li>
</ul>
</div>
</div>
<div id="standardized-difference-d-cohens-d" class="section level2">
<h2>Standardized Difference <em>d</em> (Cohen’s <em>d</em>)</h2>
<p>The standardized difference can be obtained through the
standardization of linear model’s parameters or data, in which they can
be used as indices of effect size.</p>
<div id="cohen1988statistical-1" class="section level4">
<h4><span class="citation">J. Cohen (1988)</span></h4>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">interpret_cohens_d</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1988&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>d &lt; 0.2</strong> - Very small</p></li>
<li><p><strong>0.2 &lt;= d &lt; 0.5</strong> - Small</p></li>
<li><p><strong>0.5 &lt;= d &lt; 0.8</strong> - Medium</p></li>
<li><p><strong>d &gt;= 0.8</strong> - Large</p></li>
</ul>
</div>
<div id="sawilowsky2009new" class="section level4">
<h4><span class="citation">Sawilowsky (2009)</span></h4>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">interpret_cohens_d</span>(x, <span class="at">rules =</span> <span class="st">&quot;sawilowsky2009&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>d &lt; 0.1</strong> - Tiny</p></li>
<li><p><strong>0.1 &lt;= d &lt; 0.2</strong> - Very small</p></li>
<li><p><strong>0.2 &lt;= d &lt; 0.5</strong> - Small</p></li>
<li><p><strong>0.5 &lt;= d &lt; 0.8</strong> - Medium</p></li>
<li><p><strong>0.8 &lt;= d &lt; 1.2</strong> - Large</p></li>
<li><p><strong>1.2 &lt;= d &lt; 2</strong> - Very large</p></li>
<li><p><strong>d &gt;= 2</strong> - Huge</p></li>
</ul>
</div>
<div id="gignac2016effect-1" class="section level4">
<h4><span class="citation">Gignac and Szodorai (2016)</span></h4>
<p>Gignac’s rules of thumb are actually one of few interpretation grid
justified and based on actual data, in this case on the distribution of
effect magnitudes in the literature. These is in fact the same grid used
for <em>r</em>, based on the conversion of <em>r</em> to <em>d</em>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">interpret_cohens_d</span>(x, <span class="at">rules =</span> <span class="st">&quot;gignac2016&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>d &lt; 0.2</strong> - Very small</p></li>
<li><p><strong>0.2 &lt;= d &lt; 0.41</strong> - Small</p></li>
<li><p><strong>0.41 &lt;= d &lt; 0.63</strong> - Moderate</p></li>
<li><p><strong>d &gt;= 0.63</strong> - Large</p></li>
</ul>
</div>
<div id="lovakov2021empirically-1" class="section level4">
<h4><span class="citation">Lovakov and Agadullina (2021)</span></h4>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="fu">interpret_cohens_d</span>(x, <span class="at">rules =</span> <span class="st">&quot;lovakov2021&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>r &lt; 0.15</strong> - Very small</p></li>
<li><p><strong>0.15 &lt;= r &lt; 0.36</strong> - Small</p></li>
<li><p><strong>0.36 &lt;= r &lt; 0.65</strong> - Moderate</p></li>
<li><p><strong>r &gt;= 0.65</strong> - Large</p></li>
</ul>
</div>
</div>
<div id="odds-ratio-or" class="section level2">
<h2>Odds Ratio (OR)</h2>
<p>Odds ratio, and <em>log</em> odds ratio, are often found in
epidemiological studies. However, they are also the parameters of
<strong><em>logistic</em></strong> regressions, where they can be used
as indices of effect size. Note that the (log) odds ratio from logistic
regression coefficients are <em>unstandardized</em>, as they depend on
the scale of the predictor. In order to apply the following guidelines,
make sure you <em>standardize</em> your predictors!</p>
<p>Keep in mind that these apply to Odds <em>ratios</em>, so Odds ratio
of 10 is as extreme as a Odds ratio of 0.1 (1/10).</p>
<div id="chen2010big" class="section level4">
<h4><span class="citation">Chen, Cohen, and Chen (2010)</span></h4>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">interpret_oddsratio</span>(x, <span class="at">rules =</span> <span class="st">&quot;chen2010&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>OR &lt; 1.68</strong> - Very small</p></li>
<li><p><strong>1.68 &lt;= OR &lt; 3.47</strong> - Small</p></li>
<li><p><strong>3.47 &lt;= OR &lt; 6.71</strong> - Medium</p></li>
<li><p><strong>OR &gt;= 6.71 </strong> - Large</p></li>
</ul>
</div>
<div id="cohen1988statistical-2" class="section level4">
<h4><span class="citation">J. Cohen (1988)</span></h4>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">interpret_oddsratio</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1988&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>OR &lt; 1.44</strong> - Very small</p></li>
<li><p><strong>1.44 &lt;= OR &lt; 2.48</strong> - Small</p></li>
<li><p><strong>2.48 &lt;= OR &lt; 4.27</strong> - Medium</p></li>
<li><p><strong>OR &gt;= 4.27 </strong> - Large</p></li>
</ul>
<p>This converts (log) odds ratio to standardized difference <em>d</em>
using the following formula <span class="citation">(J. Cohen 1988;
Sánchez-Meca, Marı́n-Martı́nez, and Chacón-Moscoso 2003)</span>:</p>
<p><span class="math display">\[
d = log(OR) \times \frac{\sqrt{3}}{\pi}
\]</span></p>
</div>
</div>
<div id="coefficient-of-determination-r2" class="section level2">
<h2>Coefficient of determination (R<sup>2</sup>)</h2>
<div id="for-linear-regression" class="section level3">
<h3>For Linear Regression</h3>
<div id="cohen1988statistical-3" class="section level4">
<h4><span class="citation">J. Cohen (1988)</span></h4>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">interpret_r2</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1988&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>R2 &lt; 0.02</strong> - Very weak</p></li>
<li><p><strong>0.02 &lt;= R2 &lt; 0.13</strong> - Weak</p></li>
<li><p><strong>0.13 &lt;= R2 &lt; 0.26</strong> - Moderate</p></li>
<li><p><strong>R2 &gt;= 0.26</strong> - Substantial</p></li>
</ul>
</div>
<div id="falk1992primer" class="section level4">
<h4><span class="citation">Falk and Miller (1992)</span></h4>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">interpret_r2</span>(x, <span class="at">rules =</span> <span class="st">&quot;falk1992&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>R2 &lt; 0.1</strong> - Negligible</p></li>
<li><p><strong>R2 &gt;= 0.1</strong> - Adequate</p></li>
</ul>
</div>
</div>
<div id="for-pls-sem-r-squared-of-latent-variables" class="section level3">
<h3>For PLS / SEM R-Squared of <em>latent</em> variables</h3>
<div id="chin1998partial" class="section level4">
<h4><span class="citation">Chin et al. (1998)</span></h4>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="fu">interpret_r2</span>(x, <span class="at">rules =</span> <span class="st">&quot;chin1998&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>R2 &lt; 0.19</strong> - Very weak</p></li>
<li><p><strong>0.19 &lt;= R2 &lt; 0.33</strong> - Weak</p></li>
<li><p><strong>0.33 &lt;= R2 &lt; 0.67</strong> - Moderate</p></li>
<li><p><strong>R2 &gt;= 0.67</strong> - Substantial</p></li>
</ul>
</div>
<div id="hair2011pls" class="section level4">
<h4><span class="citation">Hair, Ringle, and Sarstedt (2011)</span></h4>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">interpret_r2</span>(x, <span class="at">rules =</span> <span class="st">&quot;hair2011&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>R2 &lt; 0.25</strong> - Very weak</p></li>
<li><p><strong>0.25 &lt;= R2 &lt; 0.50</strong> - Weak</p></li>
<li><p><strong>0.50 &lt;= R2 &lt; 0.75</strong> - Moderate</p></li>
<li><p><strong>R2 &gt;= 0.75</strong> - Substantial</p></li>
</ul>
</div>
</div>
</div>
<div id="omega-eta-epsilon-squared" class="section level2">
<h2>Omega / Eta / Epsilon Squared</h2>
<p>The Omega squared is a measure of effect size used in ANOVAs. It is
an estimate of how much variance in the response variables are accounted
for by the explanatory variables. Omega squared is widely viewed as a
lesser biased alternative to eta-squared, especially when sample sizes
are small.</p>
<div id="field2013discovering" class="section level4">
<h4><span class="citation">Field (2013)</span></h4>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">interpret_omega_squared</span>(x, <span class="at">rules =</span> <span class="st">&quot;field2013&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>ES &lt; 0.01</strong> - Very small</p></li>
<li><p><strong>0.01 &lt;= ES &lt; 0.06</strong> - Small</p></li>
<li><p><strong>0.06 &lt;= ES &lt; 0.14</strong> - Medium</p></li>
<li><p><strong>ES &gt;= 0.14 </strong> - Large</p></li>
</ul>
</div>
<div id="cohen1992power" class="section level4">
<h4><span class="citation">Jacob Cohen (1992)</span></h4>
<p>These are applicable to one-way ANOVAs, or to <em>partial</em> Eta /
Omega / Epsilon Squared in a multi-way ANOVA.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">interpret_omega_squared</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1992&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>ES &lt; 0.02</strong> - Very small</p></li>
<li><p><strong>0.02 &lt;= ES &lt; 0.13</strong> - Small</p></li>
<li><p><strong>0.13 &lt;= ES &lt; 0.26</strong> - Medium</p></li>
<li><p><strong>ES &gt;= 0.26</strong> - Large</p></li>
</ul>
</div>
</div>
<div id="kendalls-coefficient-of-concordance" class="section level2">
<h2>Kendall’s coefficient of concordance</h2>
<p>The interpretation of Kendall’s coefficient of concordance
(<em>w</em>) is a measure of effect size used in non-parametric ANOVAs
(the Friedman rank sum test). It is an estimate of agreement among
multiple raters.</p>
<div id="landis1977measurement" class="section level4">
<h4><span class="citation">Landis and Koch (1977)</span></h4>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a><span class="fu">interpret_omega_squared</span>(w, <span class="at">rules =</span> <span class="st">&quot;landis1977&quot;</span>)</span></code></pre></div>
<ul>
<li><strong>0.00 &lt;= w &lt; 0.20</strong> - Slight agreement</li>
<li><strong>0.20 &lt;= w &lt; 0.40</strong> - Fair agreement</li>
<li><strong>0.40 &lt;= w &lt; 0.60</strong> - Moderate agreement</li>
<li><strong>0.60 &lt;= w &lt; 0.80</strong> - Substantial agreement</li>
<li><strong>w &gt;= 0.80</strong> - Almost perfect agreement</li>
</ul>
</div>
</div>
<div id="cohens-g" class="section level2">
<h2>Cohen’s <em>g</em></h2>
<p>Cohen’s <em>g</em> is a measure of effect size used for McNemar’s
test of agreement in selection - when repeating a multiple chose
selection, is the percent of matches (first response is equal to the
second response) different than 50%?</p>
<div id="cohen1988statistical-4" class="section level4">
<h4><span class="citation">J. Cohen (1988)</span></h4>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">interpret_cohens_g</span>(x, <span class="at">rules =</span> <span class="st">&quot;cohen1988&quot;</span>)</span></code></pre></div>
<ul>
<li><p><strong>d &lt; 0.05</strong> - Very small</p></li>
<li><p><strong>0.05 &lt;= d &lt; 0.15</strong> - Small</p></li>
<li><p><strong>0.15 &lt;= d &lt; 0.25</strong> - Medium</p></li>
<li><p><strong>d &gt;= 0.25</strong> - Large</p></li>
</ul>
</div>
</div>
<div id="interpretation-of-other-indices" class="section level2">
<h2>Interpretation of other Indices</h2>
<p><code>effectsize</code> also offers functions for interpreting other
statistical indices:</p>
<ul>
<li><p><code>interpret_gfi()</code>, <code>interpret_agfi()</code>,
<code>interpret_nfi()</code>, <code>interpret_nnfi()</code>,
<code>interpret_cfi()</code>, <code>interpret_rmsea()</code>,
<code>interpret_srmr()</code>, <code>interpret_rfi()</code>,
<code>interpret_ifi()</code>, and <code>interpret_pnfi()</code> for
interpretation CFA / SEM goodness of fit.</p></li>
<li><p><code>interpret_p()</code> for interpretation of
<em>p</em>-values.</p></li>
<li><p><code>interpret_direction()</code> for interpretation of
direction.</p></li>
<li><p><code>interpret_bf()</code> for interpretation of Bayes
factors.</p></li>
<li><p><code>interpret_rope()</code> for interpretation of Bayesian ROPE
tests.</p></li>
<li><p><code>interpret_ess()</code> and <code>interpret_rhat()</code>
for interpretation of Bayesian diagnostic indices.</p></li>
</ul>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-chen2010big" class="csl-entry">
Chen, Henian, Patricia Cohen, and Sophie Chen. 2010. <span>“How Big Is a
Big Odds Ratio? Interpreting the Magnitudes of Odds Ratios in
Epidemiological Studies.”</span> <em>Communications in
Statistics—Simulation and Computation<span></span></em> 39 (4): 860–64.
</div>
<div id="ref-chin1998partial" class="csl-entry">
Chin, Wynne W et al. 1998. <span>“The Partial Least Squares Approach to
Structural Equation Modeling.”</span> <em>Modern Methods for Business
Research</em> 295 (2): 295–336.
</div>
<div id="ref-cohen1988statistical" class="csl-entry">
Cohen, J. 1988. <em>Statistical Power Analysis for the Behavioral
Sciences, 2nd Ed.</em> New York: Routledge.
</div>
<div id="ref-cohen1992power" class="csl-entry">
Cohen, Jacob. 1992. <span>“A Power Primer.”</span> <em>Psychological
Bulletin</em> 112 (1): 155.
</div>
<div id="ref-evans1996straightforward" class="csl-entry">
Evans, James D. 1996. <em>Straightforward Statistics for the Behavioral
Sciences.</em> Thomson Brooks/Cole Publishing Co.
</div>
<div id="ref-falk1992primer" class="csl-entry">
Falk, R Frank, and Nancy B Miller. 1992. <em>A Primer for Soft
Modeling.</em> University of Akron Press.
</div>
<div id="ref-field2013discovering" class="csl-entry">
Field, Andy. 2013. <em>Discovering Statistics Using IBM SPSS
Statistics</em>. sage.
</div>
<div id="ref-funder2019evaluating" class="csl-entry">
Funder, David C, and Daniel J Ozer. 2019. <span>“Evaluating Effect Size
in Psychological Research: Sense and Nonsense.”</span> <em>Advances in
Methods and Practices in Psychological Science</em>, 2515245919847202.
</div>
<div id="ref-gignac2016effect" class="csl-entry">
Gignac, Gilles E, and Eva T Szodorai. 2016. <span>“Effect Size
Guidelines for Individual Differences Researchers.”</span>
<em>Personality and Individual Differences</em> 102: 74–78.
</div>
<div id="ref-hair2011pls" class="csl-entry">
Hair, Joe F, Christian M Ringle, and Marko Sarstedt. 2011.
<span>“PLS-SEM: Indeed a Silver Bullet.”</span> <em>Journal of Marketing
Theory and Practice</em> 19 (2): 139–52.
</div>
<div id="ref-landis1977measurement" class="csl-entry">
Landis, J Richard, and Gary G Koch. 1977. <span>“The Measurement of
Observer Agreement for Categorical Data.”</span> <em>Biometrics</em>,
159–74.
</div>
<div id="ref-lovakov2021empirically" class="csl-entry">
Lovakov, Andrey, and Elena R Agadullina. 2021. <span>“Empirically
Derived Guidelines for Effect Size Interpretation in Social
Psychology.”</span> <em>European Journal of Social Psychology</em>.
</div>
<div id="ref-sanchez2003effect" class="csl-entry">
Sánchez-Meca, Julio, Fulgencio Marı́n-Martı́nez, and Salvador
Chacón-Moscoso. 2003. <span>“Effect-Size Indices for Dichotomized
Outcomes in Meta-Analysis.”</span> <em>Psychological Methods</em> 8 (4):
448.
</div>
<div id="ref-sawilowsky2009new" class="csl-entry">
Sawilowsky, Shlomo S. 2009. <span>“New Effect Size Rules of
Thumb.”</span>
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
