<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: eta^2 and Other Effect Size for ANOVA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for eta_squared {effectsize}"><tr><td>eta_squared {effectsize}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2><i>&eta;^2</i> and Other Effect Size for ANOVA</h2>

<h3>Description</h3>

<p>Functions to compute effect size measures for ANOVAs, such as Eta-
(<i>&eta;</i>), Omega- (<i>&omega;</i>) and Epsilon- (<i>&epsilon;</i>) squared,
and Cohen's f (or their partialled versions) for ANOVA tables. These indices
represent an estimate of how much variance in the response variables is
accounted for by the explanatory variable(s).
<br /><br />
When passing models, effect sizes are computed using the sums of squares
obtained from <code>anova(model)</code> which might not always be appropriate. See
details.
</p>


<h3>Usage</h3>

<pre>
eta_squared(
  model,
  partial = TRUE,
  generalized = FALSE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

omega_squared(
  model,
  partial = TRUE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

epsilon_squared(
  model,
  partial = TRUE,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

cohens_f(
  model,
  partial = TRUE,
  generalized = FALSE,
  squared = FALSE,
  method = c("eta", "omega", "epsilon"),
  model2 = NULL,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

cohens_f_squared(
  model,
  partial = TRUE,
  generalized = FALSE,
  squared = TRUE,
  method = c("eta", "omega", "epsilon"),
  model2 = NULL,
  ci = 0.95,
  alternative = "greater",
  verbose = TRUE,
  ...
)

eta_squared_posterior(
  model,
  partial = TRUE,
  generalized = FALSE,
  ss_function = stats::anova,
  draws = 500,
  verbose = TRUE,
  ...
)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>model</code></td>
<td>
<p>An ANOVA table (or an ANOVA-like table, e.g., outputs from
<code>parameters::model_parameters</code>), or a statistical model for which such a
table can be extracted. See details.</p>
</td></tr>
<tr valign="top"><td><code>partial</code></td>
<td>
<p>If <code>TRUE</code>, return partial indices.</p>
</td></tr>
<tr valign="top"><td><code>generalized</code></td>
<td>
<p>A character vector of observed (non-manipulated) variables
to be used in the estimation of a generalized Eta Squared. Can also be
<code>TRUE</code>, in which case generalized Eta Squared is estimated assuming <em>none</em>
of the variables are observed (all are manipulated). (For <code>afex_aov</code>
models, when <code>TRUE</code>, the observed variables are extracted automatically
from the fitted model, if they were provided during fitting.</p>
</td></tr>
<tr valign="top"><td><code>ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr valign="top"><td><code>alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"greater"</code> (default) or <code>"less"</code>
(one-sided CI), or <code>"two.sided"</code> (two-sided CI). Partial matching is
allowed (e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See <em>One-Sided CIs</em> in
<a href="../../effectsize/help/effectsize_CIs.html">effectsize_CIs</a>.</p>
</td></tr>
<tr valign="top"><td><code>verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Arguments passed to or from other methods.
</p>

<ul>
<li><p> Can be <code>include_intercept = TRUE</code> to include the effect size for the intercept (when it is included in the ANOVA table).
</p>
</li>
<li><p> For Bayesian models, arguments passed to <code>ss_function</code>.
</p>
</li></ul>
</td></tr>
<tr valign="top"><td><code>squared</code></td>
<td>
<p>Return Cohen's <em>f</em> or Cohen's <em>f</em>-squared?</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>What effect size should be used as the basis for Cohen's <em>f</em>?</p>
</td></tr>
<tr valign="top"><td><code>model2</code></td>
<td>
<p>Optional second model for Cohen's f (/squared). If specified,
returns the effect size for R-squared-change between the two models.</p>
</td></tr>
<tr valign="top"><td><code>ss_function</code></td>
<td>
<p>For Bayesian models, the function used to extract
sum-of-squares. Uses <code><a href="../../stats/html/anova.html">anova()</a></code> by default, but can also be <code>car::Anova()</code>
for simple linear models.</p>
</td></tr>
<tr valign="top"><td><code>draws</code></td>
<td>
<p>For Bayesian models, an integer indicating the number of draws
from the posterior predictive distribution to return. Larger numbers take
longer to run, but provide estimates that are more stable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>aov</code> (or <code>lm</code>), <code>aovlist</code> and <code>afex_aov</code> models, and for <code>anova</code> objects
that provide Sums-of-Squares, the effect sizes are computed directly using
Sums-of-Squares. (For <code>maov</code> (or <code>mlm</code>) models, effect sizes are computed for
each response separately.)
<br /><br />
For other ANOVA tables and models (converted to ANOVA-like tables via
<code>anova()</code> methods), effect sizes are approximated via test statistic
conversion of the omnibus <em>F</em> statistic provided by the (see <code><a href="../../effectsize/help/F_to_eta2.html">F_to_eta2()</a></code>
for more details.)
</p>


<h4>Type of Sums of Squares</h4>

<p>When <code>model</code> is a statistical model, the sums of squares (or <em>F</em> statistics)
used for the computation of the effect sizes are based on those returned by
<code>anova(model)</code>. Different models have different default output type. For
example, for <code>aov</code> and <code>aovlist</code> these are <em>type-1</em> sums of squares, but for
<code>lmerMod</code> (and <code>lmerModLmerTest</code>) these are <em>type-3</em> sums of squares. Make
sure these are the sums of squares you are interested in. You might want to
convert your model to an ANOVA(-like) table yourself and then pass the result
to <code>eta_squared()</code>. See examples below for use of <code>car::Anova()</code> and the
<code>afex</code> package.
<br /><br />
For type 3 sum of squares, it is generally recommended to fit models with
<em>orthogonal factor weights</em> (e.g., <code>contr.sum</code>) and <em>centered covariates</em>,
for sensible results. See examples and the <code>afex</code> package.
</p>



<h4>Un-Biased Estimate of Eta</h4>

<p>Both <em><strong>Omega</strong></em> and <em><strong>Epsilon</strong></em> are unbiased estimators of the
population's <em><strong>Eta</strong></em>, which is especially important is small samples. But
which to choose?
<br /><br />
Though Omega is the more popular choice (Albers and Lakens, 2018), Epsilon is
analogous to adjusted R2 (Allen, 2017, p. 382), and has been found to be less
biased (Carroll &amp; Nordholm, 1975).
</p>



<h4>Cohen's f</h4>

<p>Cohen's f can take on values between zero, when the population means are all
equal, and an indefinitely large number as standard deviation of means
increases relative to the average standard deviation within each group.
<br /><br />
When comparing two models in a sequential regression analysis, Cohen's f for
R-square change is the ratio between the increase in R-square
and the percent of unexplained variance.
<br /><br />
Cohen has suggested that the values of 0.10, 0.25, and 0.40 represent small,
medium, and large effect sizes, respectively.
</p>



<h4>Eta Squared from Posterior Predictive Distribution</h4>

<p>For Bayesian models (fit with <code>brms</code> or <code>rstanarm</code>),
<code>eta_squared_posterior()</code> simulates data from the posterior predictive
distribution (ppd) and for each simulation the Eta Squared is computed for
the model's fixed effects. This means that the returned values are the
population level effect size as implied by the posterior model (and not the
effect size in the sample data). See <code><a href="../../rstantools/help/posterior_predict.html">rstantools::posterior_predict()</a></code> for
more info.
</p>



<h3>Value</h3>

<p>A data frame with the effect size(s) between 0-1 (<code>Eta2</code>, <code>Epsilon2</code>,
<code>Omega2</code>, <code>Cohens_f</code> or <code>Cohens_f2</code>, possibly with the <code>partial</code> or
<code>generalized</code> suffix), and their CIs (<code>CI_low</code> and <code>CI_high</code>).
<br /><br />
For <code>eta_squared_posterior()</code>, a data frame containing the ppd of the Eta
squared for each fixed effect, which can then be passed to
<code><a href="../../bayestestR/help/describe_posterior.html">bayestestR::describe_posterior()</a></code> for summary stats.
</p>
<p>A data frame containing the effect size values and their confidence
intervals.
</p>


<h3>Confidence (Compatibility) Intervals (CIs)</h3>

<p>Unless stated otherwise, confidence (compatibility) intervals (CIs) are
estimated using the noncentrality parameter method (also called the &quot;pivot
method&quot;). This method finds the noncentrality parameter (&quot;<em>ncp</em>&quot;) of a
noncentral <em>t</em>, <em>F</em>, or <i>&chi;^2</i> distribution that places the observed
<em>t</em>, <em>F</em>, or <i>&chi;^2</i> test statistic at the desired probability point of
the distribution. For example, if the observed <em>t</em> statistic is 2.0, with 50
degrees of freedom, for which cumulative noncentral <em>t</em> distribution is <em>t</em> =
2.0 the .025 quantile (answer: the noncentral <em>t</em> distribution with <em>ncp</em> =
.04)? After estimating these confidence bounds on the <em>ncp</em>, they are
converted into the effect size metric to obtain a confidence interval for the
effect size (Steiger, 2004).
<br /><br />
For additional details on estimation and troubleshooting, see <a href="../../effectsize/help/effectsize_CIs.html">effectsize_CIs</a>.
</p>


<h3>CIs and Significance Tests</h3>

<p>&quot;Confidence intervals on measures of effect size convey all the information
in a hypothesis test, and more.&quot; (Steiger, 2004). Confidence (compatibility)
intervals and p values are complementary summaries of parameter uncertainty
given the observed data. A dichotomous hypothesis test could be performed
with either a CI or a p value. The 100 (1 - <i>&alpha;</i>)% confidence
interval contains all of the parameter values for which <em>p</em> &gt; <i>&alpha;</i>
for the current data and model. For example, a 95% confidence interval
contains all of the values for which p &gt; .05.
<br /><br />
Note that a confidence interval including 0 <em>does not</em> indicate that the null
(no effect) is true. Rather, it suggests that the observed data together with
the model and its assumptions combined do not provided clear evidence against
a parameter value of 0 (same as with any other value in the interval), with
the level of this evidence defined by the chosen <i>&alpha;</i> level (Rafi &amp;
Greenland, 2020; Schweder &amp; Hjort, 2016; Xie &amp; Singh, 2013). To infer no
effect, additional judgments about what parameter values are &quot;close enough&quot;
to 0 to be negligible are needed (&quot;equivalence testing&quot;; Bauer &amp; Kiesser,
1996).
</p>


<h3>Plotting with <code>see</code></h3>

<p>The <code>see</code> package contains relevant plotting functions. See the <a href="https://easystats.github.io/see/articles/effectsize.html">plotting vignette in the <code>see</code> package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Albers, C., and Lakens, D. (2018). When power analyses based on pilot data
are biased: Inaccurate effect size estimators and follow-up bias. Journal of
experimental social psychology, 74, 187-195.
</p>
</li>
<li><p> Allen, R. (2017). Statistics and Experimental Design for Psychologists: A
Model Comparison Approach. World Scientific Publishing Company.
</p>
</li>
<li><p> Carroll, R. M., &amp; Nordholm, L. A. (1975). Sampling Characteristics of
Kelley's epsilon and Hays' omega. Educational and Psychological Measurement,
35(3), 541-554.
</p>
</li>
<li><p> Kelley, T. (1935) An unbiased correlation ratio measure. Proceedings of the
National Academy of Sciences. 21(9). 554-559.
</p>
</li>
<li><p> Olejnik, S., &amp; Algina, J. (2003). Generalized eta and omega squared
statistics: measures of effect size for some common research designs.
Psychological methods, 8(4), 434.
</p>
</li>
<li><p> Steiger, J. H. (2004). Beyond the F test: Effect size confidence intervals
and tests of close fit in the analysis of variance and contrast analysis.
Psychological Methods, 9, 164-182.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="../../effectsize/help/F_to_eta2.html">F_to_eta2()</a></code>
</p>
<p>Other effect sizes for ANOVAs: 
<code><a href="../../effectsize/help/rank_epsilon_squared.html">rank_epsilon_squared</a>()</code>
</p>


<h3>Examples</h3>

<pre>
data(mtcars)
mtcars$am_f &lt;- factor(mtcars$am)
mtcars$cyl_f &lt;- factor(mtcars$cyl)

model &lt;- aov(mpg ~ am_f * cyl_f, data = mtcars)

(eta2 &lt;- eta_squared(model))

# More types:
eta_squared(model, partial = FALSE)
eta_squared(model, generalized = "cyl_f")
omega_squared(model)
epsilon_squared(model)
cohens_f(model)

model0 &lt;- aov(mpg ~ am_f + cyl_f, data = mtcars) # no interaction
cohens_f_squared(model0, model2 = model)

## Interpretation of effect sizes
## ------------------------------

interpret_omega_squared(0.10, rules = "field2013")
interpret_eta_squared(0.10, rules = "cohen1992")
interpret_epsilon_squared(0.10, rules = "cohen1992")

interpret(eta2, rules = "cohen1992")


plot(eta2) # Requires the {see} package


# Recommended: Type-2 or -3 effect sizes + effects coding
# -------------------------------------------------------
contrasts(mtcars$am_f) &lt;- contr.sum
contrasts(mtcars$cyl_f) &lt;- contr.sum

model &lt;- aov(mpg ~ am_f * cyl_f, data = mtcars)
model_anova &lt;- car::Anova(model, type = 3)

epsilon_squared(model_anova)


# afex takes care of both type-3 effects and effects coding:
data(obk.long, package = "afex")
model &lt;- afex::aov_car(value ~ gender + Error(id / (phase * hour)),
  data = obk.long, observed = "gender"
)

omega_squared(model)
eta_squared(model, generalized = TRUE) # observed vars are pulled from the afex model.


## Approx. effect sizes for mixed models
## -------------------------------------
model &lt;- lme4::lmer(mpg ~ am_f * cyl_f + (1 | vs), data = mtcars)
omega_squared(model)


## Bayesian Models (PPD)
## ---------------------
fit_bayes &lt;- rstanarm::stan_glm(
  mpg ~ factor(cyl) * wt + qsec,
  data = mtcars, family = gaussian(),
  refresh = 0
)

es &lt;- eta_squared_posterior(fit_bayes,
  verbose = FALSE,
  ss_function = car::Anova, type = 3
)
bayestestR::describe_posterior(es, test = NULL)


# compare to:
fit_freq &lt;- lm(mpg ~ factor(cyl) * wt + qsec,
  data = mtcars
)
aov_table &lt;- car::Anova(fit_freq, type = 3)
eta_squared(aov_table)

</pre>

<hr /><div style="text-align: center;">[Package <em>effectsize</em> version 0.8.7 <a href="00Index.html">Index</a>]</div>
</div></body></html>
