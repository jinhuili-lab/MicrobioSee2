<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Cross-validated model performance</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for performance_cv {performance}"><tr><td>performance_cv {performance}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Cross-validated model performance</h2>

<h3>Description</h3>

<p>This function cross-validates regression models in a
user-supplied new sample or by using holdout (train-test), k-fold, or
leave-one-out cross-validation.
</p>


<h3>Usage</h3>

<pre>
performance_cv(
  model,
  data = NULL,
  method = c("holdout", "k_fold", "loo"),
  metrics = "all",
  prop = 0.3,
  k = 5,
  stack = TRUE,
  verbose = TRUE,
  ...
)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>model</code></td>
<td>
<p>A regression model.</p>
</td></tr>
<tr valign="top"><td><code>data</code></td>
<td>
<p>Optional. A data frame containing the same variables as <code>model</code>
that will be used as the cross-validation sample.</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>Character string, indicating the cross-validation method to use:
whether holdout (<code>"holdout"</code>, aka train-test), k-fold (<code>"k_fold"</code>), or
leave-one-out (<code>"loo"</code>). If <code>data</code> is supplied, this argument is ignored.</p>
</td></tr>
<tr valign="top"><td><code>metrics</code></td>
<td>
<p>Can be <code>"all"</code>, <code>"common"</code> or a character vector of metrics to be
computed (some of <code>c("ELPD", "Deviance", "MSE", "RMSE", "R2")</code>). &quot;common&quot; will
compute R2 and RMSE.</p>
</td></tr>
<tr valign="top"><td><code>prop</code></td>
<td>
<p>If <code>method = "holdout"</code>, what proportion of the sample to hold
out as the test sample?</p>
</td></tr>
<tr valign="top"><td><code>k</code></td>
<td>
<p>If <code>method = "k_fold"</code>, the number of folds to use.</p>
</td></tr>
<tr valign="top"><td><code>stack</code></td>
<td>
<p>Logical. If <code>method = "k_fold"</code>, should performance be computed
by stacking residuals from each holdout fold and calculating each metric on
the stacked data (<code>TRUE</code>, default) or should performance be computed by
calculating metrics within each holdout fold and averaging performance
across each fold (<code>FALSE</code>)?</p>
</td></tr>
<tr valign="top"><td><code>verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with columns for each metric requested, as well as <code>k</code>
if <code>method = "holdout"</code> and the <code>Method</code> used for cross-validation. If
<code>method = "holdout"</code> and <code>stack = TRUE</code>, the standard error (standard
deviation across holdout folds) for each metric is also included.
</p>


<h3>Examples</h3>

<pre>
model &lt;- lm(mpg ~ wt + cyl, data = mtcars)
performance_cv(model)

</pre>

<hr /><div style="text-align: center;">[Package <em>performance</em> version 0.11.0 <a href="00Index.html">Index</a>]</div>
</div></body></html>
