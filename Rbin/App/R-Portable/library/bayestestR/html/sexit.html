<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Sequential Effect eXistence and sIgnificance Testing (SEXIT)</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for sexit {bayestestR}"><tr><td>sexit {bayestestR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Sequential Effect eXistence and sIgnificance Testing (SEXIT)</h2>

<h3>Description</h3>

<p>The SEXIT is a new framework to describe Bayesian effects, guiding which
indices to use. Accordingly, the <code>sexit()</code> function returns the minimal (and
optimal) required information to describe models' parameters under a Bayesian
framework. It includes the following indices:
</p>

<ul>
<li><p>Centrality: the median of the posterior distribution. In
probabilistic terms, there is <code style="white-space: pre;">50%</code> of probability that the effect is higher
and lower. See <code><a href="../../bayestestR/help/point_estimate.html">point_estimate()</a></code>.
</p>
</li>
<li><p>Uncertainty: the <code style="white-space: pre;">95%</code> Highest Density Interval (HDI). In
probabilistic terms, there is <code style="white-space: pre;">95%</code> of probability that the effect is
within this confidence interval. See <code><a href="../../bayestestR/help/ci.html">ci()</a></code>.
</p>
</li>
<li><p>Existence: The probability of direction allows to quantify the
certainty by which an effect is positive or negative. It is a critical
index to show that an effect of some manipulation is not harmful (for
instance in clinical studies) or to assess the direction of a link. See
<code><a href="../../bayestestR/help/p_direction.html">p_direction()</a></code>.
</p>
</li>
<li><p>Significance: Once existence is demonstrated with high certainty, we
can assess whether the effect is of sufficient size to be considered as
significant (i.e., not negligible). This is a useful index to determine
which effects are actually important and worthy of discussion in a given
process. See <code><a href="../../bayestestR/help/p_significance.html">p_significance()</a></code>.
</p>
</li>
<li><p>Size: Finally, this index gives an idea about the strength of an
effect. However, beware, as studies have shown that a big effect size can
be also suggestive of low statistical power (see details section).
</p>
</li></ul>



<h3>Usage</h3>

<pre>
sexit(x, significant = "default", large = "default", ci = 0.95, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>A vector representing a posterior distribution, a data frame of
posterior draws (samples be parameter). Can also be a Bayesian model.</p>
</td></tr>
<tr valign="top"><td><code>significant, large</code></td>
<td>
<p>The threshold values to use for significant and
large probabilities. If left to 'default', will be selected through
<code><a href="../../bayestestR/help/sexit_thresholds.html">sexit_thresholds()</a></code>. See the details section below.</p>
</td></tr>
<tr valign="top"><td><code>ci</code></td>
<td>
<p>Value or vector of probability of the (credible) interval - CI
(between 0 and 1) to be estimated. Default to <code>.95</code> (<code style="white-space: pre;">95%</code>).</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Rationale</h4>

<p>The assessment of &quot;significance&quot; (in its broadest meaning) is a pervasive
issue in science, and its historical index, the p-value, has been strongly
criticized and deemed to have played an important role in the replicability
crisis. In reaction, more and more scientists have tuned to Bayesian methods,
offering an alternative set of tools to answer their questions. However, the
Bayesian framework offers a wide variety of possible indices related to
&quot;significance&quot;, and the debate has been raging about which index is the best,
and which one to report.
</p>
<p>This situation can lead to the mindless reporting of all possible indices
(with the hopes that with that the reader will be satisfied), but often
without having the writer understanding and interpreting them. It is indeed
complicated to juggle between many indices with complicated definitions and
subtle differences.
</p>
<p>SEXIT aims at offering a practical framework for Bayesian effects reporting,
in which the focus is put on intuitiveness, explicitness and usefulness of
the indices' interpretation. To that end, we suggest a system of description
of parameters that would be intuitive, easy to learn and apply,
mathematically accurate and useful for taking decision.
</p>
<p>Once the thresholds for significance (i.e., the ROPE) and the one for a
&quot;large&quot; effect are explicitly defined, the SEXIT framework does not make any
interpretation, i.e., it does not label the effects, but just sequentially
gives 3 probabilities (of direction, of significance and of being large,
respectively) as-is on top of the characteristics of the posterior (using the
median and HDI for centrality and uncertainty description). Thus, it provides
a lot of information about the posterior distribution (through the mass of
different 'sections' of the posterior) in a clear and meaningful way.
</p>



<h4>Threshold selection</h4>

<p>One of the most important thing about the SEXIT framework is that it relies
on two &quot;arbitrary&quot; thresholds (i.e., that have no absolute meaning). They
are the ones related to effect size (an inherently subjective notion),
namely the thresholds for significant and large effects. They are set, by
default, to <code>0.05</code> and <code>0.3</code> of the standard deviation of the outcome
variable (tiny and large effect sizes for correlations according to Funder
and Ozer, 2019). However, these defaults were chosen by lack of a better
option, and might not be adapted to your case. Thus, they are to be handled
with care, and the chosen thresholds should always be explicitly reported
and justified.
</p>

<ul>
<li><p> For <strong>linear models (lm)</strong>, this can be generalised to 0.05 * SD<sub>y</sub> and 0.3 * SD<sub>y</sub> for significant and large effects, respectively.
</p>
</li>
<li><p> For <strong>logistic models</strong>, the parameters expressed in log odds ratio can be converted to standardized difference through the formula &pi;/&radic;(3), resulting a threshold of <code>0.09</code> and <code>0.54</code>.
</p>
</li>
<li><p> For other models with <strong>binary outcome</strong>, it is strongly recommended to manually specify the rope argument. Currently, the same default is applied that for logistic models.
</p>
</li>
<li><p> For models from <strong>count data</strong>, the residual variance is used. This is a rather experimental threshold and is probably often similar to <code>0.05</code> and <code>0.3</code>, but should be used with care!
</p>
</li>
<li><p> For <strong>t-tests</strong>, the standard deviation of the response is used, similarly to linear models (see above).
</p>
</li>
<li><p> For <strong>correlations</strong>,<code>0.05</code> and <code>0.3</code> are used.
</p>
</li>
<li><p> For all other models, <code>0.05</code> and <code>0.3</code> are used, but it is strongly advised to specify it manually.
</p>
</li></ul>




<h4>Examples</h4>

<p>The three values for existence, significance and size provide a useful description of the posterior distribution of the effects. Some possible scenarios include:
</p>

<ul>
<li><p>The probability of existence is low, but the probability of being large is high: it suggests that the posterior is very wide (covering large territories on both side of 0). The statistical power might be too low, which should warrant any confident conclusion.
</p>
</li>
<li><p>The probability of existence and significance is high, but the probability of being large is very small: it suggests that the effect is, with high confidence, not large (the posterior is mostly contained between the significance and the large thresholds).
</p>
</li>
<li><p>The 3 indices are very low: this suggests that the effect is null with high confidence (the posterior is closely centred around 0).</p>
</li></ul>



<h3>Value</h3>

<p>A dataframe and text as attribute.
</p>


<h3>References</h3>


<ul>
<li><p>Makowski, D., Ben-Shachar, M. S., &amp; Lüdecke, D. (2019). bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework. Journal of Open Source Software, 4(40), 1541. doi: <a href="https://doi.org/10.21105/joss.01541">10.21105/joss.01541</a>
</p>
</li>
<li><p>Makowski D, Ben-Shachar MS, Chen SHA, Lüdecke D (2019) Indices of Effect Existence and Significance in the Bayesian Framework. Frontiers in Psychology 2019;10:2767. doi: <a href="https://doi.org/10.3389/fpsyg.2019.02767">10.3389/fpsyg.2019.02767</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre>

library(bayestestR)

s &lt;- sexit(rnorm(1000, -1, 1))
s
print(s, summary = TRUE)

s &lt;- sexit(iris)
s
print(s, summary = TRUE)

if (require("rstanarm")) {
  model &lt;- suppressWarnings(rstanarm::stan_glm(mpg ~ wt * cyl,
    data = mtcars,
    iter = 400, refresh = 0
  ))
  s &lt;- sexit(model)
  s
  print(s, summary = TRUE)
}

</pre>

<hr /><div style="text-align: center;">[Package <em>bayestestR</em> version 0.13.2 <a href="00Index.html">Index</a>]</div>
</div></body></html>
